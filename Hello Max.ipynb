{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0acacf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# My personal AI which works on voice command and face recognisation to perform basic tasks and behave as an AI chat bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7a1784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "35cc7856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import win32com.client\n",
    "import speech_recognition as sr\n",
    "import pyaudio\n",
    "import wikipedia\n",
    "import webbrowser\n",
    "import os\n",
    "import openai\n",
    "import time\n",
    "import numpy \n",
    "import requests\n",
    "import json\n",
    "import cv2\n",
    "import face_recognition\n",
    "import smtplib\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from deepface import DeepFace\n",
    "import mediapipe as mp\n",
    "from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume\n",
    "from ctypes import cast, POINTER\n",
    "from comtypes import CLSCTX_ALL\n",
    "import numpy as np\n",
    "\n",
    "query = None   # Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "09b12076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: to send gmail to anyone\n",
    "\n",
    "def send_mail(to,content):    \n",
    "\n",
    "    server = smtplib.SMTP(\"smtp.gmail.com\",\"587\")\n",
    "\n",
    "    server.ehlo()\n",
    "    server.starttls()\n",
    "    server.login(\"hk.mentor22@gmail.com\",\"cutp fhrd lclp dwyc\")\n",
    "    server.sendmail(\"hk.mentor22@gmail.com\",to,content)\n",
    "    server.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f7a718fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft David Desktop\n"
     ]
    }
   ],
   "source": [
    "# todo: set the voice for max\n",
    "\n",
    "speaker = win32com.client.Dispatch(\"SAPI.SpVoice\")\n",
    "\n",
    "voice_name = speaker.GetVoices()\n",
    "    \n",
    "print(voice_name.Item(0).GetAttribute (\"Name\"))\n",
    "\n",
    "speaker.Voice\n",
    "\n",
    "speaker.SetVoice(voice_name.Item(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f703b0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: returns text string from voice command\n",
    "\n",
    "def takecommand():\n",
    "    \n",
    "    global query\n",
    "    \n",
    "    r = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"\\nListening.....\")\n",
    "        r.pause_threshold = 1\n",
    "        audio = r.listen(source)\n",
    "        \n",
    "    try:\n",
    "        print(\"Recognising.....\")\n",
    "        query = r.recognize_google(audio,language='en-in')\n",
    "        print(f\"\\nHrithik: {query}\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"\\nSay that again please....\")\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2bf376e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: to get date and time\n",
    "\n",
    "def time_date():\n",
    "\n",
    "    timestamp = time.asctime()\n",
    "\n",
    "    timestamp_list = timestamp.split(\" \")\n",
    "\n",
    "    return timestamp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7454decb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: to get real-time weather report\n",
    "\n",
    "def get_weather(location):\n",
    "\n",
    "    param = {\n",
    "            'q': location,\n",
    "            'appid': \"e087225313f993373f0f426b53895dbb\",\n",
    "            'units': 'imperial'              # to get the temp in F\n",
    "             }\n",
    "\n",
    "    weather = requests.get(\"http://api.openweathermap.org/data/2.5/weather\",params=param)\n",
    "\n",
    "    data = weather.json()\n",
    "\n",
    "    if weather.status_code == 200:\n",
    "        #print(data)\n",
    "        temperature = data['main']['temp']\n",
    "        description = data['weather'][0]['description']\n",
    "        humidity = data['main']['humidity']\n",
    "        wind_speed = data['wind']['speed']\n",
    "\n",
    "        speaker.Speak(f\"Weather report for {location} is as follows\")\n",
    "        print(f'Temperature: {round(((int(temperature)-32)*5)/9, 1)} C')     # converted the temp to C\n",
    "        speaker.Speak(f'Temperature is {round(((int(temperature)-32)*5)/9, 1)} degree celcius')\n",
    "        print(f'Description: {description}')\n",
    "        speaker.Speak(f'Description is {description}')\n",
    "        print(f'Humidity: {humidity}%')\n",
    "        speaker.Speak(f'Humidity: {humidity}%')\n",
    "        print(f'Wind Speed is {wind_speed} m/s')\n",
    "        speaker.Speak(f'Wind Speed is {wind_speed} metre per second')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "31c67206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotion_gesture_detect():\n",
    "    \n",
    "    # Load the pre-trained Haar cascade classifier for face detection\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "    # Initialize MediaPipe hands module\n",
    "    mp_hands = mp.solutions.hands\n",
    "    hands = mp_hands.Hands(min_detection_confidence=0.7, min_tracking_confidence=0.7)\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "    # Initialize pycaw for volume control\n",
    "    devices = AudioUtilities.GetSpeakers()\n",
    "    interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
    "    volume = cast(interface, POINTER(IAudioEndpointVolume))\n",
    "\n",
    "    # Define a function to classify hand gestures\n",
    "    def classify_hand_gesture(landmarks):\n",
    "        thumb_is_open = landmarks[4].y < landmarks[3].y\n",
    "        index_is_open = landmarks[8].y < landmarks[6].y\n",
    "        middle_is_open = landmarks[12].y < landmarks[10].y\n",
    "        ring_is_open = landmarks[16].y < landmarks[14].y\n",
    "        pinky_is_open = landmarks[20].y < landmarks[18].y\n",
    "\n",
    "        current_volume = volume.GetMasterVolumeLevelScalar()\n",
    "\n",
    "        if thumb_is_open and not index_is_open and not middle_is_open and not ring_is_open and not pinky_is_open:\n",
    "            new_volume = min(current_volume + 0.0125, 1.0)  # Increase volume\n",
    "            volume.SetMasterVolumeLevelScalar(new_volume, None)\n",
    "            return \"Thumbs Up\"\n",
    "        elif not thumb_is_open and not index_is_open and not middle_is_open and not ring_is_open and not pinky_is_open:\n",
    "            new_volume = max(current_volume - 0.0125, 0.0)  # Decrease volume\n",
    "            volume.SetMasterVolumeLevelScalar(new_volume, None)\n",
    "            return \"Thumb Down\"\n",
    "        return None\n",
    "\n",
    "    # Initialize the camera\n",
    "    video = cv2.VideoCapture(0)\n",
    "\n",
    "    # Custom thresholds for each emotion\n",
    "    custom_thresholds = {\n",
    "        'angry': 0.2,\n",
    "        'disgust': 0.05,\n",
    "        'fear': 0.4,\n",
    "        'happy': 0.6,\n",
    "        'sad': 0.25,\n",
    "        'surprise': 0.35,\n",
    "        'neutral': 0.4\n",
    "    }\n",
    "\n",
    "    while True:\n",
    "        __, frame = video.read()\n",
    "        \n",
    "        # Find all face locations in the current frame\n",
    "        face_locations = face_recognition.face_locations(frame)\n",
    "\n",
    "        # Convert the frame to grayscale for face detection\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect faces in the grayscale frame\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "        # Process the image and find hands\n",
    "        results = hands.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        # Draw hand landmarks and classify gestures\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "                gesture = classify_hand_gesture(hand_landmarks.landmark)\n",
    "                if gesture:\n",
    "                    cv2.putText(frame, gesture, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Process each detected face\n",
    "        for (x, y, w, h) in faces:\n",
    "            # Extract the face region from the grayscale frame\n",
    "            face_roi = gray[y:y+h, x:x+w]\n",
    "\n",
    "            try:\n",
    "                # Convert the face region to RGB format (DeepFace requires RGB input)\n",
    "                face_rgb = cv2.cvtColor(face_roi, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "                # Perform emotion analysis on the face region\n",
    "                analyze = DeepFace.analyze(face_rgb, actions=['emotion'], enforce_detection=False)\n",
    "                \n",
    "                #Check if the result is as expected\n",
    "                emotions = analyze[0]\n",
    "                #print(\"Dominant Emotion:\", emotions['dominant_emotion'])\n",
    "                print('Face Confidence:',emotions['face_confidence'])\n",
    "                \n",
    "                \n",
    "                # Display the filtered dominant emotions on the frame    \n",
    "                dominant_emotion_text = emotions['dominant_emotion']\n",
    "                text_x = frame.shape[1] - 10 - len(dominant_emotion_text) * 20  # Adjusted position\n",
    "                text_y = 30  # Adjusted position\n",
    "                cv2.putText(frame, dominant_emotion_text, (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0,255), 2)\n",
    "    \n",
    "                # Draw a rectangle around the detected face\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "            except Exception as e:\n",
    "                print('Error analyzing face:', e)\n",
    "\n",
    "        # Display the resulting frame with detected faces and emotions\n",
    "        cv2.imshow('Face Emotion and Gesture Detection', frame)\n",
    "\n",
    "        # Check for exit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the video capture object and close all windows\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3fe35ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_detect():\n",
    "    \n",
    "    # Load a sample image of yourself\n",
    "    your_image = face_recognition.load_image_file(\"C:/Users/asus/OneDrive/Desktop/WhatsApp Image 2024-03-06 at 12.42.55_07df780f.jpg\")\n",
    "    your_encoding = face_recognition.face_encodings(your_image)[0]\n",
    "\n",
    "    # Initialize the camera\n",
    "    video = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        __, frame = video.read()\n",
    "        \n",
    "        # Find all face locations in the current frame\n",
    "        face_locations = face_recognition.face_locations(frame)\n",
    "\n",
    "        # If faces are found, try to recognize them\n",
    "        if face_locations:\n",
    "            face_encodings = face_recognition.face_encodings(frame, face_locations)\n",
    "            for face_encoding in face_encodings:\n",
    "                # Compare the current face with the known face\n",
    "                match = face_recognition.compare_faces([your_encoding], face_encoding)\n",
    "                \n",
    "                if match[0]==True:\n",
    "                    return match[0]\n",
    "                \n",
    "                else:\n",
    "                    return match[0]\n",
    "\n",
    "            \n",
    "        # Check for exit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the video capture object and close all windows\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d60d4a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    global query\n",
    "    \n",
    "    if face_detect():\n",
    "        \n",
    "        print('Face Recognised')\n",
    "        emotion_gesture_detect()\n",
    "        \n",
    "        # dictionary to store esentinal apps name and location on PC\n",
    "        app_dic = {'code':\"C:/Program Files/Microsoft Visual Studio/2022/Community/Common7/IDE/devenv.exe\",\n",
    "                'chrome':\"C:/Program Files/Google/Chrome/Application/chrome.exe\",\n",
    "                'excel':\"C:/Program Files/Microsoft Office/root/Office16/EXCEL.EXE\",\n",
    "                'word':\"C:/Program Files/Microsoft Office/root/Office16/WINWORD.EXE\",\n",
    "                'powerpoint':\"C:/Program Files/Microsoft Office/root/Office16/POWERPNT.EXE\",\n",
    "                'my pc':\"C:/Users/asus/Desktop/My PC - Shortcut.lnk\",\n",
    "                'edge':\"C:/Program Files (x86)/Microsoft/Edge/Application/msedge.exe\"}   \n",
    "        \n",
    "        get_time = time_date() \n",
    "        time = get_time[3].split(\":\")                     # to get through date and time function\n",
    "\n",
    "        if (int(time[0])>=5 and int(time[0])<12):\n",
    "            speaker.Speak(\"\\nGood morning! Hrithik\")\n",
    "\n",
    "        elif (int(time[0])>=12 and int(time[0])<18):\n",
    "            speaker.Speak(\"\\nGood afternoon! Hrithik\")\n",
    "\n",
    "        elif (int(time[0])>18):\n",
    "            speaker.Speak(\"\\nGood evening! Hrithik\")\n",
    "        \n",
    "        while True:\n",
    "\n",
    "            query = takecommand().lower()\n",
    "            #query =  input(\"Enter your command: \").lower()\n",
    "            print(query)\n",
    "\n",
    "            if 'send mail' in query:\n",
    "                speaker.Speak(\"Please tell me to whom you want to send?\")\n",
    "                #to = takecommand().lower()\n",
    "                to = input(\"To: \")\n",
    "                speaker.Speak(\"Now please tell me what you want to send?\")\n",
    "                #content = takecommand().lower()\n",
    "                content = input(\"Your Mail: \")\n",
    "                \n",
    "                try:\n",
    "                    send_mail(to,content)\n",
    "                    speaker.Speak(\"Mail has been send!\")\n",
    "\n",
    "                except exception as e:\n",
    "                    print(e)\n",
    "                    speaker.Speak(\"Sorry i am unable to send your mail right now\")\n",
    "                \n",
    "            elif \"open youtube\" in query:\n",
    "                speaker.Speak(\"Opening YouTube\")\n",
    "                webbrowser.open(\"youtube.com\")\n",
    "                \n",
    "            elif 'good bye' in query or 'goodbye' in query:\n",
    "                speaker.Speak(\"Good bye Hrithik! Have a nice day\")\n",
    "                break\n",
    "\n",
    "            elif \"google chrome\" in query:\n",
    "                speaker.Speak(\"Opening Google Chrome\")\n",
    "                os.startfile(f\"{app_dic['chrome']}\")   \n",
    "            \n",
    "            elif \"date\" in query:\n",
    "                speaker.Speak(f\"Today is {int(get_time[2])} {get_time[1]} {get_time[4]} {get_time[0]} \")\n",
    "                \n",
    "            elif \"time\" in query:\n",
    "                time_24hr_format = \"%H:%M:%S\"\n",
    "                \n",
    "                datetime_obj = datetime.strptime(time_24hr, time_24hr_format)\n",
    "                \n",
    "                time_12hr_format = datetime_obj.strftime(\"%I:%M:%S %p\")\n",
    "                \n",
    "                speaker.Speak(time_12hr_format)\n",
    "\n",
    "            elif \"hello max\" in query:\n",
    "\n",
    "                print(\"\\nHello Hrithik\\nMax here!\")\n",
    "\n",
    "                while \"bye max\" not in query or 'byemax' not in query :\n",
    "\n",
    "                    #query  = input(\"Enter your command: \")\n",
    "                    query = takecommand().lower()\n",
    "\n",
    "                    openai.api_key = \"sk-proj-vXoizBV4V0cnhqilD1PmT3BlbkFJlsljbj0ue1PNzVx2pGfZ\"\n",
    "\n",
    "                    chat_completion = openai.chat.completions.create(\n",
    "                        messages=[\n",
    "                            {\n",
    "                                \"role\": \"user\",\n",
    "                                \"content\": query,\n",
    "                            }\n",
    "                        ],\n",
    "                        temperature=1,\n",
    "                        max_tokens=4000,\n",
    "                        top_p=0.5,\n",
    "                        frequency_penalty=1,\n",
    "                        presence_penalty=1,\n",
    "                        model=\"gpt-3.5-turbo\",\n",
    "                    )\n",
    "\n",
    "                    print(f\"Max: {chat_completion.choices[0].message.content}\")\n",
    "                    speaker.Speak(chat_completion.choices[0].message.content)\n",
    "\n",
    "            elif \"code\" in query:\n",
    "                speaker.Speak(\"Opening VS Code\")\n",
    "                os.startfile(f\"{app_dic['code']}\")\n",
    "\n",
    "            elif \"excel\" in query:\n",
    "                speaker.Speak(\"Opening MS Excel\")\n",
    "                os.startfile(f\"{app_dic['excel']}\")\n",
    "\n",
    "            elif \"ms word\" in query:\n",
    "                speaker.Speak(\"Opening MS Word\")\n",
    "                os.startfile(f\"{app_dic['word']}\")\n",
    "\n",
    "            elif \"powerpoint\" in query:\n",
    "                speaker.Speak(\"Opening MS Powerpoint\")\n",
    "                os.startfile(f\"{app_dic['powerpoint']}\")\n",
    "\n",
    "            elif 'my pc' in query:\n",
    "                speaker.Speak(\"Opening My PC\")\n",
    "                os.startfile(f\"{app_dic['my pc']}\")\n",
    "\n",
    "            elif 'edge' in query:\n",
    "                speaker.Speak(\"Opening Micosoft Edge\")\n",
    "                os.startfile(f\"{app_dic['edge']}\")\n",
    "\n",
    "            elif 'weather' in query:\n",
    "                speaker.Speak(\"For which location?\")\n",
    "                get_weather(takecommand())\n",
    "                #get_weather(input(\"Location:\"))\n",
    "                \n",
    "            else:\n",
    "                speaker.Speak(\"Please! try again\")\n",
    "    else:\n",
    "        print(\"Sorry! Face not recognised\")\n",
    "        speaker.Speak(\"Sorry! face not recognised\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6e6f8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face Recognised\n",
      "Face Confidence: 0.94\n",
      "Face Confidence: 0.9\n",
      "Face Confidence: 0.91\n",
      "Face Confidence: 0.89\n",
      "Face Confidence: 0.91\n",
      "Face Confidence: 0.91\n",
      "Face Confidence: 0.9\n",
      "Face Confidence: 0.91\n",
      "Face Confidence: 0.92\n",
      "\n",
      "Listening.....\n",
      "Recognising.....\n",
      "\n",
      "Hrithik: hey Max what is the date today\n",
      "\n",
      "hey max what is the date today\n",
      "\n",
      "Listening.....\n",
      "Recognising.....\n",
      "\n",
      "Hrithik: hey Max what is the date today\n",
      "\n",
      "hey max what is the date today\n",
      "\n",
      "Listening.....\n",
      "Recognising.....\n",
      "\n",
      "Hrithik: amax what is the date today\n",
      "\n",
      "amax what is the date today\n",
      "\n",
      "Listening.....\n",
      "Recognising.....\n",
      "\n",
      "Hrithik: hey Max what is the time\n",
      "\n",
      "hey max what is the time\n",
      "\n",
      "Listening.....\n",
      "Recognising.....\n",
      "\n",
      "Hrithik: hey Max what is the date today\n",
      "\n",
      "hey max what is the date today\n",
      "\n",
      "Listening.....\n",
      "Recognising.....\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe2cb89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
